{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document clustering is explained in the diagram below. The process is as follows:  \n",
    "1. Normalization of documents has to be made if required or desired  \n",
    "2. Vectorization of the documents using representations such as:  \n",
    "    * Bag of Words (BoW)  \n",
    "    * Term frequency - Inverse Document Frequency (TF-IDF)  \n",
    "    * Word Embeddings (GloVe, Word2Vec, Transformers, BERT, etc.) with AverageEmbeddings.  \n",
    "3. If required or desired, dimensionality reduction using:  \n",
    "    * Latent Semantic Analysis (LSA).  \n",
    "    * Word Collapsing (WordNet).  \n",
    "4. Clustering documents using K-means or Gaussian Mixture Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](..//diagrams/document_clustering_diagram.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..//../techminer/'))\n",
    "from docs_normalizer import DocNormalizer\n",
    "from document_clustering import DocumentClustering\n",
    "import pandas as pd\n",
    "from techminer import RecordsDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = RecordsDataFrame(\n",
    "    pd.read_json(\n",
    "        '..\\\\..\\\\data\\\\cleaned.json', \n",
    "        orient='records', \n",
    "        lines=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_normalizer = DocNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 326 stopwords\n",
      "Normalizing documents\n"
     ]
    }
   ],
   "source": [
    "doc_normalizer.fit(rdf['Abstract'])\n",
    "rdf['Abstract_cleaned'] = doc_normalizer.transform(rdf['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vocabulary size: {len(set([word for doc in rdf.loc[:,'Abstract_cleaned'] for word in doc.split()]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_clustering = DocumentClustering(vectorize=True, \n",
    "                                         min_count=5,\n",
    "                                         max_count=1.0, \n",
    "                                         use_tfidf=True, \n",
    "                                         reduce_dimensions=True, \n",
    "                                         n_components=100,\n",
    "                                         n_clusters=6, \n",
    "                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_clustering.fit(rdf.loc[:,'Abstract_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_clustering.dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dimensions of the documents vectorized: {document_clustering.dfm.shape[0]} rows (documents) x {document_clustering.dfm.shape[1]} columns (features) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Information keeped from the dimension reduction: {round(document_clustering.explained_var_*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Information from the clusters performance: {round(document_clustering.silhouette_score_,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf['Cluster_labels'] = document_clustering.cluster_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf['Cluster_labels'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
