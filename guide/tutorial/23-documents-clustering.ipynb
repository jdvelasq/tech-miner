{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document clustering is explained in the diagram below. The process is as follows:  \n",
    "1. Normalization of documents has to be made if required or desired  \n",
    "2. Vectorization of the documents using representations such as:  \n",
    "    * Bag of Words (BoW)  \n",
    "    * Term frequency - Inverse Document Frequency (TF-IDF)  \n",
    "    * Word Embeddings (GloVe, Word2Vec, Transformers, BERT, etc.) with AverageEmbeddings.  \n",
    "3. If required or desired, dimensionality reduction using:  \n",
    "    * Latent Semantic Analysis (LSA).  \n",
    "    * Word Collapsing (WordNet).  \n",
    "4. Clustering documents using K-means or Gaussian Mixture Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](..//diagrams/document_clustering_diagram.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..//../techminer/'))\n",
    "from docs_normalizer import DocNormalizer\n",
    "from document_clustering import DocumentClustering\n",
    "import pandas as pd\n",
    "from techminer import RecordsDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = RecordsDataFrame(\n",
    "    pd.read_json(\n",
    "        'step-07.json', \n",
    "        orient='records', \n",
    "        lines=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_normalizer = DocNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 326 stopwords\n",
      "Normalizing documents\n"
     ]
    }
   ],
   "source": [
    "doc_normalizer.fit(rdf['Abstract'])\n",
    "rdf['Abstract_cleaned'] = doc_normalizer.transform(rdf['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2746\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary size: {len(set([word for doc in rdf.loc[:,'Abstract_cleaned'] for word in doc.split()]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_clustering = DocumentClustering(vectorize=True, \n",
    "                                         min_count=5,\n",
    "                                         max_count=1.0, \n",
    "                                         use_tfidf=True, \n",
    "                                         reduce_dimensions=True, \n",
    "                                         n_components=100,\n",
    "                                         n_clusters=6, \n",
    "                                         random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentClustering(max_count=1.0, min_count=5, n_clusters=6, n_components=100,\n",
       "                   random_state=42, reduce_dimensions=True, use_tfidf=True,\n",
       "                   vectorize=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_clustering.fit(rdf.loc[:,'Abstract_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.13428736e-01, -4.76060165e-02,  5.29940552e-02, ...,\n",
       "        -4.01021078e-02,  5.87939975e-02,  3.22097256e-03],\n",
       "       [ 4.71860375e-01,  1.45710210e-01, -2.84670255e-01, ...,\n",
       "         2.28289060e-02, -9.56853825e-02,  5.13728047e-02],\n",
       "       [ 6.03413082e-01, -2.90265662e-01,  4.36284296e-01, ...,\n",
       "         1.40226363e-02,  1.05095781e-02,  1.55980547e-02],\n",
       "       ...,\n",
       "       [ 4.46258507e-01,  7.62377289e-01,  2.30886605e-01, ...,\n",
       "         2.96174282e-04,  6.35138520e-03, -2.24497242e-02],\n",
       "       [ 4.32616139e-01,  1.74846432e-01,  3.16626155e-01, ...,\n",
       "         2.82303028e-02, -9.16002390e-02, -3.84914296e-02],\n",
       "       [ 5.23728023e-01,  4.36412038e-01,  1.75262218e-01, ...,\n",
       "         4.89726965e-02,  1.56163155e-01,  9.69715171e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_clustering.dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the documents vectorized: 144 rows (documents) x 100 columns (features) \n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensions of the documents vectorized: {document_clustering.dfm.shape[0]} rows (documents) x {document_clustering.dfm.shape[1]} columns (features) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information keeped from the dimension reduction: 90.21%\n"
     ]
    }
   ],
   "source": [
    "print(f'Information keeped from the dimension reduction: {round(document_clustering.explained_var_*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information from the clusters performance: 0.055\n"
     ]
    }
   ],
   "source": [
    "print(f'Information from the clusters performance: {round(document_clustering.silhouette_score_,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf['Cluster_labels'] = document_clustering.cluster_labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    97\n",
       "0    25\n",
       "5    10\n",
       "3     6\n",
       "4     3\n",
       "2     3\n",
       "Name: Cluster_labels, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf['Cluster_labels'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
