{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Record selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the records for the study are selected. The previous file is loaded with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv('demo-merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the pandas.DataFrame is converted to a `'RecordsDataFrame'` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from techminer import RecordsDataFrame\n",
    "rdf = RecordsDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from techminer import nan2none\n",
    "rdf = nan2none(rdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record selection is based in the presence or ausence of terms in each row of a dataframe.\n",
    "\n",
    "To mark the registers, two new columns called `'INCLUDE'` and `'EXCLUDE'` will be created. Each of them is Boolean. In this tutorial, we call group to this class of columns.  \n",
    "\n",
    "In the next code, both columns are created with a default value of `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf['SELECTED'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TechMiner** implements the `displayRecords()` to visualize a portion of a dataframe in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Record index: 0\n",
      "{\n",
      "  \"Author Keywords\": null,\n",
      "  \"Index Keywords\": \"Algorithmic trading; Experimental demonstrations; Fibre-optic communication; Signal transmission; State-of-the-art technology; Transmission bandwidth; Wavelength division multiplexed; Wide bandwidth; Bandwidth; Data communication systems; Fibers; Glass fibers; Light transmission; Light velocity; Optical fibers; Supercomputers; Vacuum; Wave transmission\",\n",
      "  \"Title\": \"Towards high-capacity fibre-optic communications at the speed of light in vacuum\"\n",
      "}\n",
      "-----------------------------------------------\n",
      "Record index: 1\n",
      "{\n",
      "  \"Author Keywords\": \"High-frequency trading; Limit order markets; Liquidity; Market quality; NASDAQ; Order placement strategies\",\n",
      "  \"Index Keywords\": null,\n",
      "  \"Title\": \"Low-latency trading\"\n",
      "}\n",
      "-----------------------------------------------\n",
      "Record index: 2\n",
      "{\n",
      "  \"Author Keywords\": null,\n",
      "  \"Index Keywords\": null,\n",
      "  \"Title\": \"Rise of the machines: Algorithmic trading in the foreign exchange market\"\n",
      "}\n",
      "-----------------------------------------------\n",
      "Record index: 3\n",
      "{\n",
      "  \"Author Keywords\": null,\n",
      "  \"Index Keywords\": \"competition (economics); financial market; market system; price dynamics; time series; trade\",\n",
      "  \"Title\": \"The high-frequency trading arms race: Frequent batch auctions as a market design response\"\n",
      "}\n",
      "-----------------------------------------------\n",
      "Record index: 4\n",
      "{\n",
      "  \"Author Keywords\": \"High-frequency trading; Market making; Market quality; Volatility\",\n",
      "  \"Index Keywords\": null,\n",
      "  \"Title\": \"The diversity of high-frequency traders\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from techminer import display_records\n",
    "\n",
    "display_records(rdf[['Title', 'Author Keywords', 'Index Keywords']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords completation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step aims to create a column (field) in the dataframe containing key terms for document selection. First, the columns `'Author Keywords'` and `'Index Keywords'` are joined using the `'merge_fields'` function. The new column is called `'keywords'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Algorithmic trading;Experimental demonstration...\n",
       "1    High-frequency trading;Limit order markets;Liq...\n",
       "2                                                 None\n",
       "3    competition (economics);financial market;marke...\n",
       "4    High-frequency trading;Market making;Market qu...\n",
       "5    Financial disclosure;Individual characteristic...\n",
       "6                                                 None\n",
       "7    Automated social engineering;Online privacy;On...\n",
       "8                                                 None\n",
       "9                                                 None\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from techminer import merge_fields\n",
    "merge_fields(rdf['Author Keywords'], rdf['Index Keywords'], sepA=';', sepB=';')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf['keywords'] = merge_fields(rdf['Author Keywords'], rdf['Index Keywords'], sepA=';', sepB=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are 51 records without `'Author Keywords'` and `'Index Keywords'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdf[rdf['keywords'].map(lambda x: x is None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(location-based) publish/subscribe',\n",
       " '10-fold cross-validation',\n",
       " '?-stable processes',\n",
       " 'ABM',\n",
       " 'ACE',\n",
       " 'ADALINE',\n",
       " 'ADCC-GARCH',\n",
       " 'AI techniques',\n",
       " 'ANFIS',\n",
       " 'ANFIS ensemble']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from techminer.keywords import Keywords\n",
    "kyw = Keywords()\n",
    "kyw.add_keywords(rdf['keywords'], sep=';')\n",
    "kyw._keywords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove copyright\n",
    "import numpy as np\n",
    "rdf['Abstract'] = rdf['Abstract'].map(lambda x: x[0:x.find('\\u00a9')] if isinstance(x, str) and x.find('\\u00a9')!= -1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_abstract =  merge_fields(rdf['Title'], rdf['Abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## se extrae del titulo y del abstract\n",
    "keywords_title_abstract = title_abstract.map(lambda x: kyw.extract_from(x, sep=';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = rdf['keywords'].map(lambda x: x is None)\n",
    "rdf.loc[idx, 'keywords'] = keywords_title_abstract[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rdf[rdf['keywords'].map(lambda x: x is None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Eliminaci√≥n de conferencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Keywords()\n",
    "conf.add_keywords(['Conference', 'Proceeding', 'Workshop'], sep=';')\n",
    "rdf['CONF'] = rdf['Title'].map(lambda x: True if x in conf else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICSIT 2019 - 10th International Conference on Society and Information Technologies, Proceedings\n",
      "International Conference on Digital Science, DSIC 2018\n",
      "ACM International Conference Proceeding Series\n",
      "Proceedings - 23rd IEEE International Conference on High Performance Computing Workshops, HiPCW 2016\n",
      "Workshop on Logistik und Echtzeit, Echtzeit 2017\n",
      "4th Workshop on Engineering Applications, WEA 2017\n",
      "10th International Conference on Knowledge Science, Engineering and Management, KSEM 2017\n",
      "19th International Conference on Business Information Systems, BIS 2016\n",
      "SISY 2015 - IEEE 13th International Symposium on Intelligent Systems and Informatics, Proceedings\n",
      "Proceedings - 2013 Tools and Methods of Program Analysis, TMPA 2013\n",
      "International Workshops on Business Information Systems, BIS 2015\n",
      "2015 National Conference on Parallel Computing Technologies, PARCOMPTECH 2015\n",
      "7th European Workshop on Probabilistic Graphical Models, PGM 2014\n",
      "Self-Organizing Systems - 7th IFIP TC 6 International Workshop, IWSOS 2013, Revised Selected Papers\n",
      "Modeling Decisions for Artificial Intelligence - 8th International Conference, MDAI 2011, Proceedings\n",
      "8th International Conference on Modeling Decisions for Artificial Intelligence, MDAI 2011\n",
      "Advances in Artificial Intelligence, SBIA 2010 - 20th Brazilian Symposium on Artificial Intelligence, Proceedings\n",
      "9th IFIP WG 6.1 Conference on e-Business, e-Services and e-Society, I3E 2009\n"
     ]
    }
   ],
   "source": [
    "for title in rdf[rdf['CONF']]['Title']:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528\n",
      "510\n"
     ]
    }
   ],
   "source": [
    "print(len(rdf))\n",
    "rdf = rdf[rdf['CONF'].map(lambda x: False if x is True else True)]\n",
    "print(len(rdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## Limpieza de palabras clave\n",
    "##\n",
    "from techminer import Thesaurus, text_clustering\n",
    "th = text_clustering(rdf['keywords'], sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf['keywords (cleaned)'] = rdf['keywords'].map(lambda x: th.apply(x, sep=';'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual review using external software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to save the dataframe to disk for manual review using, for example, an external editor. In the following code, the columns `'Title'`, `'Author Keywords'`, `'Index Keywords'`, `'Abstract'`, `'INCLUDE'` and `'EXCLUDE'` are saved in json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[['Title', 'Author Keywords', 'Index Keywords', 'Abstract', 'SELECTED']].to_json(\n",
    "    'demo-records.json', \n",
    "    orient='records', \n",
    "    lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following figure, a partial view of the file is presented. Note that the use of json format allows the user to identify easily each field. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screen_capture_4.jpg](screen_capture_4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing of duplicated records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Records with the same title are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n",
      "504\n"
     ]
    }
   ],
   "source": [
    "from techminer import remove_duplicate_records\n",
    "\n",
    "print(len(rdf))\n",
    "rdf = remove_duplicate_records(rdf, fields='Title', matchType='fingerprint')\n",
    "print(len(rdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the changes in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.to_json(\n",
    "    'cleaned-records.json', \n",
    "    orient='records', \n",
    "    lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
